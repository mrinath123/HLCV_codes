{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import einops\n",
    "from einops import rearrange, reduce , repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProj(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin = nn.Linear(28*28*3 , 8)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #print(x.shape)\n",
    "        x = rearrange(x , 'b p p1 p2 c -> b p (p1 p2 c)' )\n",
    "        #print(x.shape)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LinearProj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.randn(2, 4,28, 28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = l(p)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dimension = 8\n",
    "class VITblock(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(model_dimension)\n",
    "        self.norm2 = nn.LayerNorm(model_dimension)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(model_dimension , model_dimension)\n",
    "        )\n",
    "        self.MHSA = nn.MultiheadAttention(embed_dim = model_dimension, num_heads = 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x is of shape (bs x no. of patches x model_dimension )\n",
    "        x1 = self.norm1(x)\n",
    "        x2,_ = self.MHSA(x1,x1,x1)\n",
    "        x  = x2 + x\n",
    "\n",
    "        x3 = self.norm2(x)\n",
    "        x4 = self.mlp(x3)\n",
    "        x  = x4 + x\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = VITblock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 8])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v(p).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5854, -0.7514,  0.2198,  0.0442,  0.5123,  0.4325, -1.5617,\n",
       "          -1.4152],\n",
       "         [-0.1297,  0.5873,  1.1905,  0.3146, -0.0548,  0.8600, -0.9206,\n",
       "           0.6139],\n",
       "         [ 0.4040, -0.0265,  0.4570, -0.1232,  1.3797,  1.3209, -0.4143,\n",
       "          -1.0343],\n",
       "         [-1.3091, -0.1063, -0.9931,  0.9654,  1.5126,  1.3525,  0.7966,\n",
       "          -1.0016]],\n",
       "\n",
       "        [[ 0.4665, -0.9921, -0.3968, -1.5002, -0.4527, -0.5212, -1.4241,\n",
       "          -1.6723],\n",
       "         [ 0.7723, -0.7284, -0.4974,  1.1497,  0.3244, -1.0656,  1.4813,\n",
       "          -0.5505],\n",
       "         [-0.5572,  1.0361,  0.1432, -0.0859, -0.1507,  0.7860,  0.4746,\n",
       "           1.7172],\n",
       "         [-0.4817,  0.4083, -0.1530, -0.5637,  0.6309,  1.0865, -0.6380,\n",
       "          -1.2389]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1 , 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2520, -1.0080, -0.1512,  0.4547,  1.3315, -0.7934,  2.4654,\n",
       "           0.2535]],\n",
       "\n",
       "        [[ 2.2520, -1.0080, -0.1512,  0.4547,  1.3315, -0.7934,  2.4654,\n",
       "           0.2535]]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = repeat(x , 'a b -> r a b', r = 2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cat(( x , v(p)), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 8])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.randn(5 , 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (x + p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2596, -0.0104,  0.9144,  0.1786,  1.1872, -1.6954,  2.0234,\n",
       "           0.0288],\n",
       "         [-0.6215, -1.5826, -0.4923, -0.2332,  0.6252, -0.0492, -0.2681,\n",
       "          -1.9030],\n",
       "         [ 0.0706, -1.0837,  0.2758,  1.1160,  0.5501,  1.3569, -2.0969,\n",
       "          -0.7577],\n",
       "         [ 0.5817, -1.5051,  0.3715, -2.4433,  1.9197,  0.2633,  0.0136,\n",
       "          -0.7897],\n",
       "         [-2.0136,  0.6554, -1.9909,  2.0055,  2.0433,  2.9869, -0.3803,\n",
       "          -2.1213]],\n",
       "\n",
       "        [[ 2.2596, -0.0104,  0.9144,  0.1786,  1.1872, -1.6954,  2.0234,\n",
       "           0.0288],\n",
       "         [ 0.4304, -1.8233, -1.1088, -1.7776, -0.3398, -1.0029, -0.1306,\n",
       "          -2.1602],\n",
       "         [ 0.9726, -2.3994, -1.4122,  1.9512,  0.9293, -0.5687,  0.3050,\n",
       "          -1.9222],\n",
       "         [-0.3796, -0.4425,  0.0576, -2.4060,  0.3893, -0.2715,  0.9025,\n",
       "           1.9618],\n",
       "         [-1.1861,  1.1700, -1.1507,  0.4764,  1.1616,  2.7209, -1.8149,\n",
       "          -2.3587]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 8])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2596, -0.0104,  0.9144,  0.1786,  1.1872, -1.6954,  2.0234,  0.0288],\n",
       "        [ 2.2596, -0.0104,  0.9144,  0.1786,  1.1872, -1.6954,  2.0234,  0.0288]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[: , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patchify(nn.Module):\n",
    "    def __init__(self , p = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self , x ):\n",
    "        x = rearrange(x , 'b (h p1) (w p2)  c -> b (p1 p2) h w c', p1=self.p, p2=self.p)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Patchify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3 , 4,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0733e+00,  1.7882e-04, -6.0929e-01],\n",
       "         [ 2.6887e-01, -5.9926e-01, -8.6274e-01],\n",
       "         [-2.5372e-01,  5.2756e-01, -1.0957e+00],\n",
       "         [ 6.2930e-01,  8.5015e-01,  8.7898e-01]],\n",
       "\n",
       "        [[-1.6170e-01,  1.1345e+00, -1.2453e-01],\n",
       "         [ 6.4747e-01,  8.0367e-01, -2.9888e-01],\n",
       "         [-9.6629e-01, -1.7787e+00, -8.0773e-01],\n",
       "         [-5.5597e-01,  8.2175e-01,  4.1799e-01]],\n",
       "\n",
       "        [[-1.7154e-01, -9.4263e-01, -7.7320e-01],\n",
       "         [-7.7652e-02, -1.1777e+00,  5.5803e-02],\n",
       "         [ 2.9365e+00,  5.1143e-01, -1.0198e+00],\n",
       "         [ 1.2620e+00, -1.6780e-01, -1.0016e+00]],\n",
       "\n",
       "        [[-6.2960e-01, -2.1806e+00, -9.5690e-01],\n",
       "         [-3.5090e-01,  9.1976e-01,  5.1849e-01],\n",
       "         [-1.5406e-01, -1.0412e+00,  1.1421e+00],\n",
       "         [-6.6721e-01, -8.5002e-01, -3.4606e-01]]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 2, 2, 3])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 2, 3])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(x)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
